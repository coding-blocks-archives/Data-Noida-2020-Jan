{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://cb.lk/speech\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"speech.txt\", \"wt\", encoding=\"utf-8\") as f:\n",
    "#     f.write(content.text)\n",
    "\n",
    "# with open(\"speech.txt\", \"rt\", encoding=\"utf-8\") as f:\n",
    "#     some_text = f.read()\n",
    "\n",
    "# print(some_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = content.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330090"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14067"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "punc = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = set(stops + punc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pure = [word for word in words if word not in bad]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154573"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "items, counts = np.unique(pure, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_indices = counts.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_indices = sorted_indices[-1000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = items[last_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = dict(zip(bag, range(len(bag))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grabbing a sent out of total speech\n",
    "\n",
    "sent = sent_tokenize(text)[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = word_tokenize(sent.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = np.zeros([len(vocab)], dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in w:\n",
    "    if word in vocab:\n",
    "        vec[vocab[word]] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CountVectorizer(min_df=20, max_df=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=20, max_features=None, min_df=20,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(sent_tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'believed': 7,\n",
       " 'transforming': 68,\n",
       " 'fall': 26,\n",
       " 'rooted': 57,\n",
       " 'procedures': 53,\n",
       " 'personally': 48,\n",
       " 'participated': 47,\n",
       " 'points': 50,\n",
       " 'transformed': 67,\n",
       " 'subject': 66,\n",
       " 'alliance': 3,\n",
       " 'cooperate': 16,\n",
       " 'identity': 35,\n",
       " 'played': 49,\n",
       " 'diabetes': 17,\n",
       " 'carry': 13,\n",
       " 'witnessed': 73,\n",
       " 'leads': 41,\n",
       " 'languages': 40,\n",
       " 'burden': 11,\n",
       " 'facility': 25,\n",
       " 'mark': 43,\n",
       " 'fought': 29,\n",
       " 'ups': 71,\n",
       " 'soldier': 63,\n",
       " 'discipline': 20,\n",
       " 'capable': 12,\n",
       " 'implemented': 37,\n",
       " 'transparency': 70,\n",
       " 'wanted': 72,\n",
       " 'transmission': 69,\n",
       " 'below': 8,\n",
       " 'expenditure': 24,\n",
       " 'black': 9,\n",
       " 'pradhan': 52,\n",
       " 'holds': 32,\n",
       " 'loss': 42,\n",
       " 'saved': 60,\n",
       " 'filled': 27,\n",
       " 'match': 44,\n",
       " 'improvement': 38,\n",
       " 'ranking': 54,\n",
       " 'spoke': 64,\n",
       " 'realise': 55,\n",
       " 'hopes': 33,\n",
       " 'brave': 10,\n",
       " 'implement': 36,\n",
       " 'sleep': 62,\n",
       " 'accordance': 1,\n",
       " 'military': 45,\n",
       " 'ideals': 34,\n",
       " 'standing': 65,\n",
       " 'equality': 22,\n",
       " 'hindi': 31,\n",
       " 'practices': 51,\n",
       " 'domestic': 21,\n",
       " 'seeking': 61,\n",
       " 'awareness': 6,\n",
       " 'accessible': 0,\n",
       " 'avoidance': 5,\n",
       " 'religious': 56,\n",
       " 'appreciate': 4,\n",
       " 'disaster': 19,\n",
       " 'running': 58,\n",
       " 'centres': 14,\n",
       " 'fiscal': 28,\n",
       " 'moved': 46,\n",
       " 'agree': 2,\n",
       " 'everybody': 23,\n",
       " 'saints': 59,\n",
       " 'congress': 15,\n",
       " 'games': 30,\n",
       " 'diamond': 18,\n",
       " 'kazakhstan': 39}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
